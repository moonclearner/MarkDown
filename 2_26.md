# word2Vec
文本表示与建模是自然语言处理领域中的基础任务。传统的文本表示方法主要是基于词袋模型，好处在于简单高效，容易扩展，但同时也面临众多严重的问题，如维度灾难、数据稀疏表示、缺失语义表达能力等。近年来随着大数据和深度学习技术在语音、图像、生物信息等领域取得重大的成果，研究者们也开始将深度神经网络技术应用到自然语言处理领域。特别地，随着 2008 年 Collobert 和 Weston 将基于深度神经网络的词向量表示应用到各类自然语言处理任务以及 2013 年谷歌研究员基于神经网络语言模型来学习分布式词向量表示，越来越多基于神经网络模型来学习文本向量表示的方法出现。本文集中对基于神经网络语言模型的文本向量表示和主题建模问题进行了研究。首先简单介绍传统 N-Gram 统计语言模型和基于神经网络的语言模型，并且回顾传统词向量表示方法以及学习分布式词向量表示模型 Word2Vec。随后基于这些基础模型与方法，
本文进行了多方面的扩展：
1. 潜在狄利克雷分布 (LDA) 挖掘文档中的主题结构，在自然语言处理和机器学习领域扮演重要的角色。然而，LDA 中的概率分布表示仅仅描述语料中的共现统计关系，概率分布并不是特征表示的最好选择。近来，基于向量表示的方法被提出来学习词和文档的概念和表示，例如 Word2Vec 向量表示方法已经在众多任务中相比类 LDA 的方法表现更好。Doc2Vec。因此，本文提出模型可以学习和词向量表示在同一个语义空间的 Topic2Vec 主题向量表示，作为概率分布的替换。实验表明可以更好的建模 Topic2Vec 主题。
2. 分布式词向量表示已经在自然语言处理领域取得了重大的成果。然而，大多数模型只关注局部上下文属性并且独自地学习特定任务的表示，缺失融合多个属性联合学习的能力。因此，本文提出一个统一的框架可以联合学习词和词的属性的分布式表示。在模型中，我们考虑了三类属性：主题、词元和文档。在学习属性的分布式向量表示的同时，我们发现利用附加的属性对于提升词的表示也是有益的。实验部分从多个方面分别评价了主题向量表示、文档向量表示和提升的词向量表示，结果表明我们的模型效果更好。
3. 感知任务例如视觉对象识别和文本理解在人类智能中起着重要的作用，后续任务则包括推断、推理和决策制定等都要求更高层次的智能。过去几年中，感知任务的主要进展均采用了深度学习模型。而对于更高层次的推断，带有贝叶斯属性的概率图模型则更加强大和灵活。为了实现整合感知任务以及高层次推断的智能，自然地希望将深度学习和贝叶斯模型紧密联合起来。本文考虑融合基于神经网络的词向量表示和潜在狄利克雷分布 (LDA)。特别地，将词向量表示应用到 LDA 中来提升原有主题模型的效果，分别提出词向量聚类先验 LDA、上下文感知 LDA 和词向量加强 LDA 等模型。实验表明利用词向量表示的 LDA 表现更好。
